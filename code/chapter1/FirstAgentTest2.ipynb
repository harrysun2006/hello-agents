{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b2e36-f95c-4b0f-8770-335c6bb5bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re, requests\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv(dotenv_path='.vscode/.env.local', override=True)\n",
    "\n",
    "llm_config = {\n",
    "    \"openai\": { # Open AI\n",
    "        \"api_key\": os.environ.get('OPENAI_API_KEY',''),\n",
    "        \"base_url\": os.environ.get('OPENAI_BASE_URL',''),\n",
    "        \"model\": os.environ.get('OPENAI_MODEL_ID',''),\n",
    "    },\n",
    "    \"azure\": { # Azure\n",
    "        \"max_tokens\": 128000,\n",
    "        \"max_chat_tokens\": 127502,\n",
    "        \"api_key\": os.environ.get('AZURE_API_KEY',''),\n",
    "        \"api_version\": os.environ.get('AZURE_API_VERSION',''),\n",
    "        \"base_url\": os.environ.get('AZURE_BASE_URL',''),\n",
    "        \"model\": os.environ.get('AZURE_MODEL_ID',''),\n",
    "    },\n",
    "    \"ollama\": {\n",
    "        \"base_url\": os.environ.get('OLLAMA_BASE_URL',''),\n",
    "        \"model\": os.environ.get('OLLAMA_MODEL_ID',''),\n",
    "    }\n",
    "}\n",
    "\n",
    "# é…ç½®APIå¯†é’¥\n",
    "LLM = os.getenv(\"LLM\", \"OPENAI\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "TIMEOUT = 90 # seconds\n",
    "\n",
    "print(os.getcwd())\n",
    "print(LLM, llm_config[LLM.lower()])\n",
    "\n",
    "# ç³»ç»Ÿæç¤ºè¯\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "# å¯ç”¨å·¥å…·:\n",
    "- `get_weather(city: str)`: æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ã€‚\n",
    "- `get_attraction(city: str, weather: str)`: æ ¹æ®åŸå¸‚å’Œå¤©æ°”æœç´¢æ¨èçš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
    "\n",
    "# è¡ŒåŠ¨æ ¼å¼:\n",
    "ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š\n",
    "Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]\n",
    "Action: [è¿™é‡Œæ˜¯ä½ è¦è°ƒç”¨çš„å·¥å…·ï¼Œæ ¼å¼ä¸º function_name(arg_name=\"arg_value\")]\n",
    "\n",
    "# ä»»åŠ¡å®Œæˆ:\n",
    "å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `finish(answer=\"...\")` æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "è¯·å¼€å§‹å§ï¼\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d9d404-3c95-42f2-8975-436769b3cb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str, **kargs) -> str:\n",
    "    \"\"\"\n",
    "    é€šè¿‡è°ƒç”¨ wttr.in API æŸ¥è¯¢çœŸå®çš„å¤©æ°”ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    # APIç«¯ç‚¹ï¼Œæˆ‘ä»¬è¯·æ±‚JSONæ ¼å¼çš„æ•°æ®\n",
    "    url = f\"https://wttr.in/{city}?format=j1\"\n",
    "    \n",
    "    try:\n",
    "        # å‘èµ·ç½‘ç»œè¯·æ±‚\n",
    "        response = requests.get(url, timeout=TIMEOUT)\n",
    "        # æ£€æŸ¥å“åº”çŠ¶æ€ç æ˜¯å¦ä¸º200 (æˆåŠŸ)\n",
    "        response.raise_for_status() \n",
    "        # è§£æè¿”å›çš„JSONæ•°æ®\n",
    "        data = response.json()\n",
    "        \n",
    "        # æå–å½“å‰å¤©æ°”çŠ¶å†µ\n",
    "        current_condition = data['current_condition'][0]\n",
    "        weather_desc = current_condition['weatherDesc'][0]['value']\n",
    "        temp_c = current_condition['temp_C']\n",
    "        \n",
    "        # æ ¼å¼åŒ–æˆè‡ªç„¶è¯­è¨€è¿”å›\n",
    "        return f\"{city}å½“å‰å¤©æ°”ï¼š{weather_desc}ï¼Œæ°”æ¸©{temp_c}æ‘„æ°åº¦\"\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # å¤„ç†ç½‘ç»œé”™è¯¯\n",
    "        return f\"é”™è¯¯ï¼šæŸ¥è¯¢å¤©æ°”æ—¶é‡åˆ°ç½‘ç»œé—®é¢˜ - {e}\"\n",
    "    except (KeyError, IndexError) as e:\n",
    "        # å¤„ç†æ•°æ®è§£æé”™è¯¯\n",
    "        return f\"é”™è¯¯ï¼šè§£æå¤©æ°”æ•°æ®å¤±è´¥ï¼Œå¯èƒ½æ˜¯åŸå¸‚åç§°æ— æ•ˆ - {e}\"\n",
    "\n",
    "def get_attraction(city: str, weather: str, **kargs) -> str:\n",
    "    \"\"\"\n",
    "    æ ¹æ®åŸå¸‚å’Œå¤©æ°”ï¼Œä½¿ç”¨Tavily Search APIæœç´¢å¹¶è¿”å›ä¼˜åŒ–åçš„æ™¯ç‚¹æ¨èã€‚\n",
    "    \"\"\"\n",
    "    api_key = TAVILY_API_KEY\n",
    "\n",
    "    if not api_key:\n",
    "        return \"é”™è¯¯ï¼šæœªé…ç½®TAVILY_API_KEYã€‚\"\n",
    "\n",
    "    # åˆå§‹åŒ–Tavilyå®¢æˆ·ç«¯\n",
    "    tavily = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    # æ„é€ ä¸€ä¸ªç²¾ç¡®çš„æŸ¥è¯¢\n",
    "    query = f\"'{city}' åœ¨'{weather}'å¤©æ°”ä¸‹æœ€å€¼å¾—å»çš„æ—…æ¸¸æ™¯ç‚¹æ¨èåŠç†ç”±\"\n",
    "    \n",
    "    try:\n",
    "        # è°ƒç”¨APIï¼Œinclude_answer=Trueä¼šè¿”å›ä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”\n",
    "        response = tavily.search(query=query, search_depth=\"basic\", include_answer=True, timeout=TIMEOUT)\n",
    "        \n",
    "        # Tavilyè¿”å›çš„ç»“æœå·²ç»éå¸¸å¹²å‡€ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨\n",
    "        if response.get(\"answer\"):\n",
    "            return response[\"answer\"]\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰ç»¼åˆæ€§å›ç­”ï¼Œåˆ™æ ¼å¼åŒ–åŸå§‹ç»“æœ\n",
    "        formatted_results = []\n",
    "        for result in response.get(\"results\", []):\n",
    "            formatted_results.append(f\"- {result['title']}: {result['content']}\")\n",
    "        \n",
    "        if not formatted_results:\n",
    "             return \"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚\"\n",
    "\n",
    "        return \"æ ¹æ®æœç´¢ï¼Œä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š\\n\" + \"\\n\".join(formatted_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"é”™è¯¯ï¼šæ‰§è¡ŒTavilyæœç´¢æ—¶å‡ºç°é—®é¢˜ - {e}\"\n",
    "\n",
    "# å°†æ‰€æœ‰å·¥å…·å‡½æ•°æ”¾å…¥ä¸€ä¸ªå­—å…¸ï¼Œæ–¹ä¾¿åç»­è°ƒç”¨\n",
    "available_tools = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_attraction\": get_attraction,\n",
    "}\n",
    "print(\"âœ… å·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e953fee4-9e3c-4e34-bf48-4ea002c3bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ™ºèƒ½åŠ©æ‰‹ç±»å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "class GPT():\n",
    "    def __init__(self, llm=\"openai\"):\n",
    "        self.llm = llm\n",
    "        self.config = llm_config[llm]\n",
    "        self.calls = {\n",
    "            \"openai\": self.call_openai,\n",
    "            \"azure\": self.call_azure,\n",
    "            \"ollama\": self.call_ollama,\n",
    "        }\n",
    "\n",
    "    # gpt-5.1 changes:\n",
    "    # url: /v1/chat/completions => /v1/responses\n",
    "    # request: messages => input\n",
    "    # response: choices => output\n",
    "    def call_openai(self, messages):\n",
    "        url = f\"{self.config['base_url']}/v1/responses\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.config['api_key']}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.config['model'],\n",
    "            \"input\": messages,\n",
    "            # \"max_tokens\": self.config['max_response_tokens'],\n",
    "            # \"response_format\": {\"type\": \"json_object\"}\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        # print(f'url={url}, headers={headers}, payload={payload}')\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, headers=headers, timeout=TIMEOUT)\n",
    "            if not response.ok:\n",
    "                print(f\"[OpenAI ERROR] status={response.status_code}, body={response.text}\")\n",
    "            response.raise_for_status()\n",
    "            # print(response.json())\n",
    "            return response.json()['output'][0]['content'][0]['text']\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while calling OpenAI GPT: {e}\")\n",
    "            # raise Exception(status_code=500, detail=detail)\n",
    "\n",
    "    def call_azure(self, messages):\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": self.config['api_key'],\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": self.config['model'],\n",
    "            \"messages\": messages,\n",
    "            # get error: 'messages' must contain the word 'json' in some form, to use 'response_format' of type 'jso\n",
    "            # \"response_format\": {\"type\": \"json_object\"}\n",
    "        }\n",
    "        # url = f\"{self.config['base_url']}/openai/deployments/{self.config['model']}/chat/completions?api-version={self.config['api_version']}\"\n",
    "        url = f\"{self.config['base_url']}/openai/v1/chat/completions\"\n",
    "        # print(f'url={url}, headers={headers}, payload={payload}')\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n",
    "            if not response.ok:\n",
    "                print(f\"[Azure ERROR] status={response.status_code}, body={response.text}\")\n",
    "            print(f\"Azure response code: {response.status_code}\")\n",
    "            response.raise_for_status()\n",
    "            # print(response.json())\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"An error occurred while calling Azure GPT: {e}\")\n",
    "            # raise HTTPException(status_code=500, detail=detail)\n",
    "    \n",
    "    def call_ollama(self, messages):\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            # \"api-key\": self.config['api_key'],\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": self.config['model'],\n",
    "            \"messages\": messages,\n",
    "            # get error: 'messages' must contain the word 'json' in some form, to use 'response_format' of type 'jso\n",
    "            # \"response_format\": {\"type\": \"json_object\"}\n",
    "        }\n",
    "        url = f\"{self.config['base_url']}/v1/chat/completions\"\n",
    "        print(f'url={url}, headers={headers}, payload={payload}')\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload, timeout=600)\n",
    "            if not response.ok:\n",
    "                print(f\"[Ollama ERROR] status={response.status_code}, body={response.text}\")\n",
    "            print(f\"Ollama response code: {response.status_code}\")\n",
    "            response.raise_for_status()\n",
    "            # print(response.json())\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"An error occurred while calling Ollama GPT: {e}\")\n",
    "            # raise HTTPException(status_code=500, detail=detail)\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM APIæ¥ç”Ÿæˆå›åº”ã€‚\"\"\"\n",
    "        print(\"æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\")\n",
    "        try:\n",
    "            messages = [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ]\n",
    "            response = self.calls[self.llm](messages)\n",
    "            # answer = response.choices[0].message.content\n",
    "            # answer = response.replace('```', '').replace('json', '')\n",
    "            answer = response\n",
    "            print(\"å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\")\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            return \"é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\"\n",
    "\n",
    "class TravelAssistant:\n",
    "    \"\"\"\n",
    "    æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ç±»\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = GPT(llm=LLM.lower())\n",
    "        self.prompt_history = []\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"é‡ç½®å¯¹è¯å†å²\"\"\"\n",
    "        self.prompt_history = []\n",
    "    \n",
    "    def add_user_message(self, message: str):\n",
    "        \"\"\"æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(f\"ç”¨æˆ·è¯·æ±‚: {message}\")\n",
    "    \n",
    "    def add_assistant_message(self, message: str):\n",
    "        \"\"\"æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(message)\n",
    "    \n",
    "    def add_observation(self, observation: str):\n",
    "        \"\"\"æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(f\"Observation: {observation}\")\n",
    "print(\"âœ… æ™ºèƒ½åŠ©æ‰‹ç±»å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5d3142-c119-46ad-a7a1-ec1aa2e79435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ˜¾ç¤ºå‡½æ•°å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def display_conversation(history):\n",
    "    \"\"\"ç¾è§‚åœ°æ˜¾ç¤ºå¯¹è¯å†å²\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ å¯¹è¯å†å²\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, message in enumerate(history, 1):\n",
    "        if message.startswith(\"ç”¨æˆ·è¯·æ±‚:\"):\n",
    "            print(f\"\\nğŸ‘¤ ç”¨æˆ· [{i}]: {message[5:].replace('\\\\n', '\\n')}\")\n",
    "        elif message.startswith(\"Thought:\"):\n",
    "            print(f\"\\nğŸ¤” æ€è€ƒ [{i}]: {message[8:].strip().replace('\\\\n', '\\n')}\")\n",
    "        elif message.startswith(\"Action:\"):\n",
    "            print(f\"ğŸ› ï¸ è¡ŒåŠ¨ [{i}]: {message[7:].strip().replace('\\\\n', '\\n')}\")\n",
    "        elif message.startswith(\"Observation:\"):\n",
    "            print(f\"ğŸ“Š è§‚å¯Ÿ [{i}]: {message[12:].strip().replace('\\\\n', '\\n')}\")\n",
    "        else:\n",
    "            print(f\"ğŸ’¬ æ¶ˆæ¯ [{i}]: {message.replace('\\\\n', '\\n')}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def parse_action(action_str):\n",
    "    \"\"\"è§£æè¡ŒåŠ¨å­—ç¬¦ä¸²\"\"\"\n",
    "    if action_str.startswith(\"finish\"):\n",
    "        match = re.search(r'finish\\(answer=\"(.*)\"\\)', action_str)\n",
    "        if match:\n",
    "            return \"finish\", {\"answer\": match.group(1)}\n",
    "        return \"finish\", {\"answer\": \"ä»»åŠ¡å®Œæˆ\"}\n",
    "    \n",
    "    tool_name_match = re.search(r\"(\\w+)\\(\", action_str)\n",
    "    if not tool_name_match:\n",
    "        return None, {}\n",
    "    \n",
    "    tool_name = tool_name_match.group(1)\n",
    "    args_match = re.search(r\"\\((.*)\\)\", action_str)\n",
    "    if args_match:\n",
    "        args_str = args_match.group(1)\n",
    "        kwargs = dict(re.findall(r'(\\w+)=\"([^\"]*)\"', args_str))\n",
    "    else:\n",
    "        kwargs = {}\n",
    "    \n",
    "    return tool_name, kwargs\n",
    "print(\"âœ… æ˜¾ç¤ºå‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc543309-fe16-44a9-9735-bce828b9c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(user_input, max_iterations=5, display=True):\n",
    "    \"\"\"\n",
    "    è¿è¡Œæ—…è¡ŒåŠ©æ‰‹çš„ä¸»å‡½æ•°\n",
    "    \n",
    "    Args:\n",
    "        user_input: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜\n",
    "        max_iterations: æœ€å¤§å¾ªç¯æ¬¡æ•°\n",
    "        display: æ˜¯å¦æ˜¾ç¤ºå¯¹è¯å†å²\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (æœ€ç»ˆç­”æ¡ˆ, å®Œæ•´çš„å¯¹è¯å†å²)\n",
    "    \"\"\"\n",
    "    assistant = TravelAssistant()\n",
    "    assistant.add_user_message(user_input)\n",
    "    \n",
    "    if display:\n",
    "        print(f\"ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_input}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        if display:\n",
    "            print(f\"\\nğŸ”„ å¾ªç¯ {i+1}/{max_iterations}\")\n",
    "        \n",
    "        # æ„å»ºå®Œæ•´promptå¹¶è°ƒç”¨LLM\n",
    "        full_prompt = \"\\n\".join(assistant.prompt_history)\n",
    "        llm_output = assistant.llm.generate(full_prompt, AGENT_SYSTEM_PROMPT)\n",
    "        # æ¨¡å‹å¯èƒ½ä¼šè¾“å‡ºå¤šä½™çš„Thought-Actionï¼Œéœ€è¦æˆªæ–­\n",
    "        match = re.search(r'(Thought:.*?Action:.*?)(?=\\n\\s*(?:Thought:|Action:|Observation:)|\\Z)', llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            truncated = match.group(1).strip()\n",
    "            if truncated != llm_output.strip():\n",
    "                llm_output = truncated\n",
    "                print(\"âš ï¸ å·²æˆªæ–­å¤šä½™çš„ Thought-Action å¯¹\")\n",
    "        \n",
    "        assistant.add_assistant_message(llm_output)\n",
    "        \n",
    "        if display:\n",
    "            print(f\"ğŸ¤– æ¨¡å‹è¾“å‡º:\\n{llm_output.replace('\\\\n', '\\n')}\")\n",
    "        \n",
    "        # è§£æè¡ŒåŠ¨\n",
    "        action_match = re.search(r\"Action: (.*)\", llm_output, re.DOTALL)\n",
    "        if not action_match:\n",
    "            print(\"âŒ è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚\")\n",
    "            break\n",
    "            \n",
    "        action_str = action_match.group(1).strip()\n",
    "        tool_name, kwargs = parse_action(action_str)\n",
    "        \n",
    "        # å¤„ç†å®Œæˆè¡ŒåŠ¨\n",
    "        if tool_name == \"finish\":\n",
    "            final_answer = kwargs.get(\"answer\", \"ä»»åŠ¡å®Œæˆ\")\n",
    "            if display:\n",
    "                print(f\"ğŸ‰ ä»»åŠ¡å®Œæˆ!\")\n",
    "                # print(f\"ğŸ“‹ æœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "                print(f\"ğŸ“‹ æœ€ç»ˆç­”æ¡ˆ: {final_answer.replace('\\\\n', '\\n')}\")\n",
    "            return final_answer, assistant.prompt_history\n",
    "        \n",
    "        # å¤„ç†å·¥å…·è°ƒç”¨\n",
    "        if tool_name in available_tools:\n",
    "            if display:\n",
    "                print(f\"ğŸ› ï¸ è°ƒç”¨å·¥å…·: {tool_name}({kwargs})\")\n",
    "            observation = available_tools[tool_name](**kwargs)\n",
    "        else:\n",
    "            observation = f\"é”™è¯¯ï¼šæœªå®šä¹‰çš„å·¥å…· '{tool_name}'\"\n",
    "        \n",
    "        # è®°å½•è§‚å¯Ÿç»“æœ\n",
    "        if display:\n",
    "            print(f\"ğŸ“Š è§‚å¯Ÿç»“æœ: {observation.replace('\\\\n', '\\n')}\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        assistant.add_observation(observation)\n",
    "    \n",
    "    # å¦‚æœè¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ä»æœªå®Œæˆ\n",
    "    timeout_answer = \"æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\"\n",
    "    if display:\n",
    "        print(f\"â° è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°: {timeout_answer}\")\n",
    "    \n",
    "    return timeout_answer, assistant.prompt_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f6e44eb-ff3d-4060-b4c2-ea3e139bf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èç¤ºä¾‹\n",
      "ğŸ‘¤ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 1/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "Azure response code: 200\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: é¦–å…ˆéœ€è¦è·å–åŒ—äº¬ä»Šå¤©çš„å®æ—¶å¤©æ°”ï¼Œä»¥ä¾¿åç»­é€‰æ‹©åˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚  \n",
      "Action: get_weather(city=\"åŒ—äº¬\")\n",
      "ğŸ› ï¸ è°ƒç”¨å·¥å…·: get_weather({'city': 'åŒ—äº¬'})\n",
      "ğŸ“Š è§‚å¯Ÿç»“æœ: åŒ—äº¬å½“å‰å¤©æ°”ï¼šSunnyï¼Œæ°”æ¸©3æ‘„æ°åº¦\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 2/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "Azure response code: 200\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: æ ¹æ®å½“å‰å¤©æ°”æƒ…å†µSunnyï¼Œæ¥ä¸‹æ¥è°ƒç”¨æ™¯ç‚¹æ¨èæ¥å£è·å–åˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹  \n",
      "Action: get_attraction(city=\"åŒ—äº¬\", weather=\"Sunny\")\n",
      "ğŸ› ï¸ è°ƒç”¨å·¥å…·: get_attraction({'city': 'åŒ—äº¬', 'weather': 'Sunny'})\n",
      "ğŸ“Š è§‚å¯Ÿç»“æœ: Under sunny weather, Forbidden City and Great Wall are top Beijing attractions. Both offer rich history and stunning views.\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 3/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "Azure response code: 200\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: å·²è·å–åŒ—äº¬å½“å‰å¤©æ°”å’Œæ¨èæ™¯ç‚¹ï¼Œå¯ä»¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ  \n",
      "Action: finish(answer=\"ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©çº¦3â„ƒã€‚æ¨èæ‚¨å‰å¾€æ•…å®«æˆ–é•¿åŸæ¸¸è§ˆï¼Œè¿™ä¸¤ä¸ªæ™¯ç‚¹å†å²æ‚ ä¹…ã€æ™¯è‰²å£®ä¸½ï¼Œéå¸¸é€‚åˆåœ¨æ™´å¥½å¤©æ°”ä¸‹å‚è§‚ã€‚\")\n",
      "ğŸ‰ ä»»åŠ¡å®Œæˆ!\n",
      "ğŸ“‹ æœ€ç»ˆç­”æ¡ˆ: ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©çº¦3â„ƒã€‚æ¨èæ‚¨å‰å¾€æ•…å®«æˆ–é•¿åŸæ¸¸è§ˆï¼Œè¿™ä¸¤ä¸ªæ™¯ç‚¹å†å²æ‚ ä¹…ã€æ™¯è‰²å£®ä¸½ï¼Œéå¸¸é€‚åˆåœ¨æ™´å¥½å¤©æ°”ä¸‹å‚è§‚ã€‚\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š æµ‹è¯•å®Œæˆ!\n",
      "============================================================\n",
      "æœ€ç»ˆç­”æ¡ˆ: ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©çº¦3â„ƒã€‚æ¨èæ‚¨å‰å¾€æ•…å®«æˆ–é•¿åŸæ¸¸è§ˆï¼Œè¿™ä¸¤ä¸ªæ™¯ç‚¹å†å²æ‚ ä¹…ã€æ™¯è‰²å£®ä¸½ï¼Œéå¸¸é€‚åˆåœ¨æ™´å¥½å¤©æ°”ä¸‹å‚è§‚ã€‚\n",
      "\n",
      "============================================================\n",
      "ğŸ“ å¯¹è¯å†å²\n",
      "============================================================\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ· [1]:  ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "\n",
      "ğŸ¤” æ€è€ƒ [2]: é¦–å…ˆéœ€è¦è·å–åŒ—äº¬ä»Šå¤©çš„å®æ—¶å¤©æ°”ï¼Œä»¥ä¾¿åç»­é€‰æ‹©åˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚  \n",
      "Action: get_weather(city=\"åŒ—äº¬\")\n",
      "ğŸ“Š è§‚å¯Ÿ [3]: åŒ—äº¬å½“å‰å¤©æ°”ï¼šSunnyï¼Œæ°”æ¸©3æ‘„æ°åº¦\n",
      "\n",
      "ğŸ¤” æ€è€ƒ [4]: æ ¹æ®å½“å‰å¤©æ°”æƒ…å†µSunnyï¼Œæ¥ä¸‹æ¥è°ƒç”¨æ™¯ç‚¹æ¨èæ¥å£è·å–åˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹  \n",
      "Action: get_attraction(city=\"åŒ—äº¬\", weather=\"Sunny\")\n",
      "ğŸ“Š è§‚å¯Ÿ [5]: Under sunny weather, Forbidden City and Great Wall are top Beijing attractions. Both offer rich history and stunning views.\n",
      "\n",
      "ğŸ¤” æ€è€ƒ [6]: å·²è·å–åŒ—äº¬å½“å‰å¤©æ°”å’Œæ¨èæ™¯ç‚¹ï¼Œå¯ä»¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ  \n",
      "Action: finish(answer=\"ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©çº¦3â„ƒã€‚æ¨èæ‚¨å‰å¾€æ•…å®«æˆ–é•¿åŸæ¸¸è§ˆï¼Œè¿™ä¸¤ä¸ªæ™¯ç‚¹å†å²æ‚ ä¹…ã€æ™¯è‰²å£®ä¸½ï¼Œéå¸¸é€‚åˆåœ¨æ™´å¥½å¤©æ°”ä¸‹å‚è§‚ã€‚\")\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ç¤ºä¾‹\n",
    "def test_basic_example():\n",
    "    \"\"\"æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èçš„ç¤ºä¾‹\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èç¤ºä¾‹\")\n",
    "    user_input = \"ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\"\n",
    "    \n",
    "    final_answer, history = run_assistant(user_input, display=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š æµ‹è¯•å®Œæˆ!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"æœ€ç»ˆç­”æ¡ˆ: {final_answer.replace('\\\\n', '\\n')}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²\n",
    "    display_conversation(history)\n",
    "    \n",
    "    return final_answer, history\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•ç¤ºä¾‹\n",
    "final_answer, history = test_basic_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68c735c1-eb3e-40e7-8b70-2be941798187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_travel_assistant():\n",
    "    \"\"\"\n",
    "    äº¤äº’å¼æ—…è¡ŒåŠ©æ‰‹\n",
    "    \"\"\"\n",
    "    print(\"ğŸŒ æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹!\")\n",
    "    print(\"ğŸ’¡ æ‚¨å¯ä»¥è¯¢é—®ä»»ä½•åŸå¸‚çš„å¤©æ°”å’Œæ—…æ¸¸æ™¯ç‚¹æ¨è\")\n",
    "    print(\"âŒ è¾“å…¥ 'quit' æˆ– 'é€€å‡º' æ¥ç»“æŸå¯¹è¯\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'é€€å‡º', 'exit']:\n",
    "            print(\"ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼Œå†è§!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            print(\"âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...\")\n",
    "        \n",
    "        final_answer, history = run_assistant(user_input, display=True)\n",
    "        \n",
    "        print(\"\\nğŸ¯ æœ€ç»ˆå›ç­”:\")\n",
    "        print(\"=\"*30)\n",
    "        print(final_answer)\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²\n",
    "        show_history = input(\"\\nğŸ“– æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²? (y/n): \").strip().lower()\n",
    "        if show_history in ['y', 'yes', 'æ˜¯']:\n",
    "            display_conversation(history)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ”„ å‡†å¤‡æ¥å—ä¸‹ä¸€ä¸ªé—®é¢˜...\\n\")\n",
    "\n",
    "# å¿«é€Ÿæµ‹è¯•å‡½æ•°\n",
    "def quick_test(city=\"ä¸Šæµ·\"):\n",
    "    \"\"\"å¿«é€Ÿæµ‹è¯•æŒ‡å®šåŸå¸‚çš„å¤©æ°”å’Œæ™¯ç‚¹\"\"\"\n",
    "    user_input = f\"è¯·å¸®æˆ‘æŸ¥è¯¢{city}çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆçš„æ—…æ¸¸æ™¯ç‚¹\"\n",
    "    print(f\"ğŸš€ å¿«é€Ÿæµ‹è¯•: {user_input}\")\n",
    "    final_answer, _ = run_assistant(user_input, display=True)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc58c911-8502-4cf5-aa3f-a9f57a94b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é€‰æ‹©è¿è¡Œæ¨¡å¼:\n",
      "1. è¿è¡Œæµ‹è¯•ç¤ºä¾‹ (åŒ—äº¬)\n",
      "2. äº¤äº’æ¨¡å¼\n",
      "3. å¿«é€Ÿæµ‹è¯•å…¶ä»–åŸå¸‚\n",
      "ğŸŒ æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹!\n",
      "ğŸ’¡ æ‚¨å¯ä»¥è¯¢é—®ä»»ä½•åŸå¸‚çš„å¤©æ°”å’Œæ—…æ¸¸æ™¯ç‚¹æ¨è\n",
      "âŒ è¾“å…¥ 'quit' æˆ– 'é€€å‡º' æ¥ç»“æŸå¯¹è¯\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...\n",
      "ğŸ‘¤ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©å¢¨å°”æœ¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªä¸‰å¤©ä¸¤æ™šçš„æ—…æ¸¸è®¡åˆ’ã€‚\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 1/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: ç”¨æˆ·æƒ³äº†è§£ä»Šå¤©å¢¨å°”æœ¬çš„å®æ—¶å¤©æ°”ï¼Œå†æ ¹æ®å¤©æ°”åˆ¶å®šä¸‰å¤©ä¸¤æ™šè¡Œç¨‹ã€‚ç¬¬ä¸€æ­¥å…ˆæŸ¥è¯¢å¢¨å°”æœ¬å¤©æ°”ï¼Œæ‹¿åˆ°ç»“æœåå†æ ¹æ®è¯¥å¤©æ°”è°ƒç”¨æ™¯ç‚¹æ¨èå·¥å…·ï¼Œæœ€åæ•´åˆæˆè¯¦ç»†è¡Œç¨‹è§„åˆ’ã€‚\n",
      "Action: get_weather(city=\"å¢¨å°”æœ¬\")\n",
      "ğŸ› ï¸ è°ƒç”¨å·¥å…·: get_weather({'city': 'å¢¨å°”æœ¬'})\n",
      "ğŸ“Š è§‚å¯Ÿç»“æœ: å¢¨å°”æœ¬å½“å‰å¤©æ°”ï¼šOvercastï¼Œæ°”æ¸©16æ‘„æ°åº¦\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 2/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: Request timed out.\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\n",
      "âŒ è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚\n",
      "â° è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°: æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\n",
      "\n",
      "ğŸ¯ æœ€ç»ˆå›ç­”:\n",
      "==============================\n",
      "æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\n",
      "==============================\n",
      "\n",
      "============================================================\n",
      "ğŸ”„ å‡†å¤‡æ¥å—ä¸‹ä¸€ä¸ªé—®é¢˜...\n",
      "\n",
      "âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜\n",
      "ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼Œå†è§!\n"
     ]
    }
   ],
   "source": [
    "# ä¸»å¯åŠ¨å…¥å£\n",
    "if __name__ == \"__main__\":\n",
    "    # å¯ä»¥é€‰æ‹©ç›´æ¥è¿è¡Œæµ‹è¯•ç¤ºä¾‹\n",
    "    print(\"é€‰æ‹©è¿è¡Œæ¨¡å¼:\")\n",
    "    print(\"1. è¿è¡Œæµ‹è¯•ç¤ºä¾‹ (åŒ—äº¬)\")\n",
    "    print(\"2. äº¤äº’æ¨¡å¼\")\n",
    "    print(\"3. å¿«é€Ÿæµ‹è¯•å…¶ä»–åŸå¸‚\")\n",
    "    \n",
    "    choice = input(\"è¯·è¾“å…¥é€‰æ‹© (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        test_basic_example()\n",
    "    elif choice == \"2\":\n",
    "        interactive_travel_assistant()\n",
    "    elif choice == \"3\":\n",
    "        city = input(\"è¯·è¾“å…¥è¦æµ‹è¯•çš„åŸå¸‚: \").strip() or \"ä¸Šæµ·\"\n",
    "        quick_test(city)\n",
    "    else:\n",
    "        print(\"æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œæµ‹è¯•ç¤ºä¾‹...\")\n",
    "        test_basic_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.12 (micromamba)",
   "language": "python",
   "name": "py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
