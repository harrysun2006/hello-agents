ä¸‹é¢æˆ‘ç»™ä½ æ¨è **ä¸“ä¸º ArchLinux + å±€åŸŸç½‘ GPU èŠ‚ç‚¹ï¼ˆOllama/TGIï¼‰+ ä¸­è‹±æ–‡æ£€ç´¢** çš„ç®€æ´å¯é  RAG æŠ€æœ¯æ ˆï¼Œå¹¶é™„å¸¦æœ€å®ç”¨çš„å®‰è£…æ­¥éª¤ï¼ˆå…¨éƒ¨æœ¬åœ°éƒ¨ç½²ã€æ— äº‘ä¾èµ–ï¼‰ã€‚

ä½ å°†å¾—åˆ°ä¸€ä¸ª **å‰ç«¯åœ¨ ArchLinuxã€æœ¬åœ°æ—  GPUï¼›åç«¯åœ¨å±€åŸŸç½‘å¦ä¸€å°å¸¦ GPU çš„æœºå™¨** çš„å…¸å‹â€œåˆ†å¸ƒå¼ RAGâ€ æ¶æ„ã€‚

---

![RAG Architecture](rag01.png)
![RAG](rag02.png)

# âœ… ä¸€ã€æ¶æ„æ¨èï¼ˆéå¸¸ç¨³å®šã€é€‚åˆä¸­è‹±æ–‡ RAGï¼‰

ä½ çš„åœºæ™¯æ˜¯ï¼š

* **ArchLinux æœ¬åœ°æœº**ï¼šè´Ÿè´£æ•°æ®ç´¢å¼•ã€å‘é‡åº“ã€RAG ç®¡é“
* **å¦ä¸€å° GPU æœºå™¨ï¼ˆå±€åŸŸç½‘ï¼‰**ï¼šè¿è¡Œ LLM æ¨ç†ï¼ˆOllama / TGIï¼‰
* **è¦æ±‚æ”¯æŒä¸­è‹±æ–‡æ£€ç´¢**

ğŸ‘‰ æ¨èæ¶æ„å¦‚ä¸‹ï¼š

```
[ ArchLinux æœ¬æœº ]
  - LlamaIndex æˆ– Haystack
  - Qdrantï¼ˆå‘é‡åº“ï¼‰
  - Embedding æ¨¡å‹ï¼ˆCPUï¼‰
  - æ§åˆ¶ RAG Pipeline

            â†“ é€šè¿‡ HTTP è°ƒç”¨ GPU
[ GPU æœºå™¨ ]
  - Ollama or TGI (Text Generation Inference)
  - åŠ é€Ÿä¸­æ–‡/è‹±æ–‡å¤§æ¨¡å‹è¾“å‡º
```

ç‰¹ç‚¹ï¼š

* **GPU èŠ‚ç‚¹åªè´Ÿè´£æ¨ç†** â†’ è´Ÿè½½æ›´è½»ï¼ŒCPU ä¸»æœºå‹åŠ›æœ€å°
* ArchLinux æœ¬åœ°æœº **ä¸éœ€è¦ GPU ä¹Ÿèƒ½é«˜é€Ÿç”Ÿæˆ embedding**ï¼ˆç”¨ CPU ç‰ˆ bge æ¨¡å‹è¶³å¤Ÿï¼‰
* ä¸­è‹±æ–‡å‡å¯ç”¨ **bge-m3** / **jina-embeddings-v2-base-zh**

---

# âœ… äºŒã€æœ¬åœ°ï¼ˆArchLinuxï¼‰æ¨èå®‰è£…ç»„ä»¶

## 1. **å‘é‡æ•°æ®åº“ï¼šQdrantï¼ˆå¼ºçƒˆæ¨èï¼‰**

Rust å†™çš„ï¼Œæ€§èƒ½é«˜ã€ç¨³å®šã€è½»é‡ã€‚

### å®‰è£…ï¼ˆArchLinux å®˜æ–¹ä»“åº“ï¼‰ï¼š

```bash
sudo pacman -S qdrant
sudo systemctl enable --now qdrant
```

é»˜è®¤ç›‘å¬ `localhost:6333`

å¦‚æœ GPU æœºå™¨ä¹Ÿéœ€è¦è®¿é—® â†’ ä¿®æ”¹é…ç½® `/etc/qdrant/config.yaml`

```yaml
service:
  host: "0.0.0.0"
  port: 6333
```

---

## 2. **RAG æ¡†æ¶ï¼šLlamaIndexï¼ˆæœ€çµæ´»ï¼‰**

ä¸­è‹±æ–‡éƒ½éå¸¸é¡ºæ‰‹ï¼Œé›†æˆ Qdrant/TGI/Ollama éå¸¸æ–¹ä¾¿ã€‚

å®‰è£…ï¼š

```bash
pip install llama-index llama-index-vector-stores-qdrant
pip install llama-index-embeddings-huggingface
```

---

## 3. **ä¸­è‹±æ–‡ Embedding æ¨¡å‹ï¼ˆCPU å‹å¥½ï¼‰**

### æ¨èï¼š

* **bge-m3**ï¼ˆè¶…å¼ºä¸­è‹±æ–‡ã€å°è¯­ç§ï¼‰
* ORï¼š`jina-embeddings-v2-base-zh`ï¼ˆä¸­æ–‡å¢å¼ºï¼‰

å®‰è£…ï¼š

```bash
pip install sentence-transformers
```

ä½¿ç”¨ bge-m3ï¼š

```python
from sentence_transformers import SentenceTransformer
emb = SentenceTransformer("BAAI/bge-m3")
```

---

# âœ… ä¸‰ã€GPU ä¸»æœºï¼ˆå±€åŸŸç½‘ï¼‰æ¨èå®‰è£…ç»„ä»¶

## æ–¹æ¡ˆ Aï¼š**Ollamaï¼ˆæœ€ç®€å•ã€åŠŸèƒ½æœ€å®Œå¤‡ï¼‰**

GPU æœºå™¨å®‰è£…ï¼š

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

å¯åŠ¨æ¨¡å‹ï¼ˆä¸­è‹±æ–‡é€šç”¨ï¼‰ï¼š

```bash
ollama pull qwen2.5:14b
ollama pull yi:9b
ollama pull llama3.1:8b
```

ç¡®è®¤ Ollama åœ¨ç›‘å¬ï¼ˆLANï¼‰ï¼š

ç¼–è¾‘ `/etc/systemd/system/ollama.service`ï¼š

```
Environment="OLLAMA_HOST=0.0.0.0"
```

ç„¶åï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl restart ollama
```

GPU æœº LLM å°†æš´éœ²åœ¨ï¼š

```
http://GPU_IP:11434/api/generate
```

---

## æ–¹æ¡ˆ Bï¼š**TGIï¼ˆHuggingFace Text Generation Inferenceï¼‰**

é€‚åˆæ¨¡å‹ > 20B æˆ–éœ€è¦æ‰¹å¤„ç†ã€‚

Docker ç¤ºä¾‹ï¼š

```bash
docker run -d --gpus all \
  -p 8080:80 \
  ghcr.io/huggingface/text-generation-inference:latest \
  --model-id Qwen/Qwen2.5-7B-Instruct
```

æœåŠ¡å°†æš´éœ²ï¼š

```
http://GPU_IP:8080
```

---

# âœ… å››ã€RAG Pipeline ä»£ç ï¼ˆä¸ä½ çš„æ¶æ„å®Œç¾åŒ¹é…ï¼‰

ä¸‹é¢æ˜¯ LlamaIndex + Qdrant + å±€åŸŸç½‘ Ollama çš„å…¸å‹ä¾‹å­ï¼š

```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.core import StorageContext
from llama_index.llms.ollama import Ollama
from sentence_transformers import SentenceTransformer
import qdrant_client

# 1. Embedding model (CPU)
embed_model = SentenceTransformer("BAAI/bge-m3")

# 2. Connect to Qdrant
client = qdrant_client.QdrantClient(url="http://127.0.0.1:6333")
vector_store = QdrantVectorStore(client=client, collection_name="docs")

storage = StorageContext.from_defaults(vector_store=vector_store)

# 3. Load documents
docs = SimpleDirectoryReader("data/").load_data()

# 4. Create Index
index = VectorStoreIndex.from_documents(
    docs,
    embed_model=embed_model,
    storage_context=storage
)

# 5. Connect to remote Ollama GPU node
llm = Ollama(
    model="qwen2.5:14b",
    base_url="http://192.168.1.88:11434"  # GPU node IP
)

query_engine = index.as_query_engine(llm=llm)

res = query_engine.query("è¯·ç”¨ä¸­æ–‡è§£é‡Šè¿™äº›æ–‡æ¡£å†…å®¹çš„æ ¸å¿ƒè¦ç‚¹")
print(res)
```

è¿™æ®µä»£ç å…·å¤‡ï¼š

* æœ¬æœº embeddingï¼ˆbgeï¼‰
* æœ¬æœº Qdrant å­˜å‚¨
* è·¨æœºè°ƒç”¨ GPU LLMï¼ˆOllamaï¼‰
* ä¸­è‹±æ–‡å‡å¯ä½¿ç”¨

ä½ åªéœ€å°†æ•°æ®æ”¾å…¥ `data/` å³å¯ã€‚

---

# âœ… äº”ã€æ¨èçš„æ•´ä½“éƒ¨ç½²æ–¹å¼ï¼ˆç¨³å®šã€ç®€å•ï¼‰

### **æœ¬æœºï¼ˆArchLinuxï¼‰ï¼š**

```
sudo pacman -S qdrant
pip install llama-index
pip install sentence-transformers
```

### **GPU æœºï¼š**

```
ollama pull qwen2.5:14b
export OLLAMA_HOST=0.0.0.0
```

### æ€»ç»“å›¾ï¼š

```
ArchLinux CPU ------------------> GPU Server
Embedding (bge)                 Ollama/TGI
Qdrant vector store             Large model inference
RAG orchestration               Fast generation
```

ä½ ä¼šå¾—åˆ°ä¸€ä¸ªï¼š

âœ” å®Œå…¨æœ¬åœ°ã€æ— äº‘
âœ” æ”¯æŒä¸­è‹±æ–‡
âœ” é«˜æ€§èƒ½
âœ” å¯æ‰©å±•
âœ” ä½è€¦åˆ

çš„ RAG ç³»ç»Ÿã€‚

---

# å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥å¸®ä½ ç”Ÿæˆï¼š

* ä¸€é”®å®‰è£…è„šæœ¬ï¼ˆfor ArchLinuxï¼‰
* ä¸€é”®å®‰è£…è„šæœ¬ï¼ˆfor GPU èŠ‚ç‚¹ï¼‰
* RAG API æœåŠ¡ï¼ˆFastAPIï¼‰æ¨¡æ¿
* ç›®å½•ç»“æ„ï¼ˆdata/index/logs/modelsï¼‰å»ºè®®
* docker-compose ç‰ˆæœ¬
* LlamaIndex ä¸ Haystack çš„å¯¹æ¯”é€‰æ‹©

ä½ æƒ³ç»§ç»­å—ï¼Ÿ


å…ˆç›´æ¥å›ç­”ç»“è®ºç‰ˆï¼Œå†ç»™ä½ ä¸€ç‚¹ã€Œæ€ä¹ˆé€‰ + æ€ä¹ˆæ qdrant-binã€çš„å…·ä½“æ“ä½œã€‚

---

## 1. LlamaIndex vs Haystackï¼šæ€ä¹ˆé€‰ï¼Ÿ

ç»“åˆä½ ç°åœ¨çš„åœºæ™¯ï¼š

* Arch æœ¬æœºè·‘ RAGã€Qdrantã€embedding
* å±€åŸŸç½‘é‡Œå¦ä¸€å° GPU è·‘ Ollama/TGI
* Python ä¸ºä¸»ï¼Œä¸ªäºº/å°è§„æ¨¡é¡¹ç›®ï¼Œå…ˆåšèµ·æ¥ï¼Œå†è€ƒè™‘å¤æ‚ pipeline

### æ ¸å¿ƒå·®å¼‚ï¼ˆè¶…ç®€åŒ–ç‰ˆæœ¬ï¼‰

| æ–¹é¢           | LlamaIndex                         | Haystack                                     |
| ------------ | ---------------------------------- | -------------------------------------------- |
| å®šä½           | â€œæ•°æ®æ¥å…¥å±‚ + RAG å¼•æ“â€                   | â€œLLM åº”ç”¨/Agent ç¼–æ’æ¡†æ¶ + RAGâ€                    |
| ä¸Šæ‰‹éš¾åº¦         | è¾ƒä½ï¼ŒAPI åã€Œå³æ’å³ç”¨ã€                     | åå·¥ç¨‹åŒ–ï¼Œéœ€è¦ç†è§£ Pipeline èŠ‚ç‚¹ã€ç»„ä»¶                     |
| æ–‡æ¡£ç±»å‹æ”¯æŒ       | å„ç§ Loader ç‰¹åˆ«å¤šï¼ŒPDF/HTML/DB/Notion ç­‰ | ä¹Ÿæ”¯æŒï¼Œä½†æ›´å¼ºè°ƒæœç´¢/QA åœºæ™¯                             |
| å‘é‡åº“é›†æˆ        | å¯¹ Qdrant/Chroma/Weaviate ç­‰é€‚é…å¾ˆå¥½     | å¯¹ Elasticsearch / OpenSearch / Qdrant ç­‰é€‚é…ä¹Ÿä¸é”™ |
| Agent / å¤šæ­¥æµç¨‹ | æœ‰ï¼Œä½†æ›´åƒåœ¨ RAG ä¹‹ä¸Šçš„é™„åŠ                    | Agent/workflow æ˜¯ä¸€ç­‰å…¬æ°‘ï¼Œé€‚åˆå¤æ‚ä¸šåŠ¡é€»è¾‘                |
| ç›‘æ§ã€å¯è§‚æµ‹æ€§      | æœ‰ tracing/Callbacksï¼Œä½†åè½»é‡           | æ›´åâ€œç”Ÿäº§çº§â€ï¼Œæœ‰æ›´å®Œå–„çš„ pipeline ç›‘æ§ã€æ—¥å¿—é›†æˆ               |
| ç¤¾åŒºç”Ÿæ€         | RAG åœºæ™¯å¾ˆæ´»è·ƒï¼Œæ•™ç¨‹å¤š                      | åœ¨â€œä¼ä¸šçº§ QA/æœç´¢ + pipelineâ€æ–¹å‘æ¯”è¾ƒå¼º                 |

### ç»™ä½ ä¸€ä¸ªã€Œä½¿ç”¨åœºæ™¯ã€çš„åˆ¤æ–­å°ºå­

**æ›´é€‚åˆ LlamaIndex çš„æƒ…å†µï¼š**

* ä½ æƒ³å…ˆæŠŠã€Œä¸ªäººçŸ¥è¯†åº“ / å†…ç½‘ docs + RAG + èŠå¤©ã€è·‘èµ·æ¥ï¼›
* å–œæ¬¢ `index.as_query_engine()` è¿™ç§ä¸€è¡Œæå®šçš„æ¥å£ï¼›
* æƒ³å¿«é€Ÿè¯•ä¸åŒå‘é‡åº“ã€åµŒå…¥æ¨¡å‹ã€LLMï¼Œè€Œä¸æ˜¯å…ˆè®¾è®¡ä¸€å † pipeline nodeï¼›
* ä¸æ€¥ç€ä¸Šé‚£ç§â€œå‡ åä¸ªèŠ‚ç‚¹çš„å·¥ä½œæµç¼–æ’â€ã€‚

**æ›´é€‚åˆ Haystack çš„æƒ…å†µï¼š**

* ä½ æ‰“ç®—åšçš„ä¸œè¥¿æ›´åƒ **æœç´¢/é—®ç­”æœåŠ¡ + å¤šé˜¶æ®µ pipeline**ï¼š

  * æ¯”å¦‚ï¼šé¢„è¿‡æ»¤ â†’ å‘é‡æ£€ç´¢ â†’ rerank â†’ LLM â†’ ç»“æ„åŒ–è¾“å‡º â†’ å†™å›æ•°æ®åº“ï¼›
* éœ€è¦å¯¹æ¯ä¸ªæ­¥éª¤åšç›‘æ§ã€è°ƒå‚ã€AB testï¼›
* æœªæ¥å¯èƒ½ä¸Šå¤šå®ä¾‹éƒ¨ç½²ï¼Œç”šè‡³ç»™å›¢é˜Ÿ/å…¬å¸ç”¨ã€‚

> ç»“åˆä½ ç°åœ¨çš„éœ€æ±‚ï¼ˆArch ä¸Šæœ¬åœ° RAGï¼Œè¿ä¸€å° GPU LLMï¼Œå…ˆæä¸ªä¸­è‹±åŒè¯­çŸ¥è¯†åº“ï¼‰ï¼š
> **æˆ‘å»ºè®®ï¼šå…ˆç”¨ LlamaIndex èµ·ç›˜**ï¼Œåé¢å¦‚æœä½ è¦åšæ›´å¤æ‚çš„ä¸šåŠ¡æµæ°´çº¿ï¼Œå†è€ƒè™‘ç”¨ Haystack é‡æ„ä¸€ç‰ˆâ€œç”Ÿäº§ç‰ˆâ€ã€‚

---

## 2. qdrant-bin æ²¡æœ‰ qdrant.service å’Œ /etc/qdrant/config.yaml æ€ä¹ˆåŠï¼Ÿ

è¿™æ˜¯ **æ­£å¸¸ç°è±¡**ï¼Œå› ä¸ºï¼š

* AUR çš„ `qdrant-bin` åªæ˜¯æŠŠå®˜æ–¹ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶è§£åŒ…åˆ° `/usr/bin/qdrant`ï¼Œæ²¡æœ‰é¢å¤–æ‰“ systemd unit æˆ–é»˜è®¤é…ç½®ï¼›ä» PKGBUILD å¯ä»¥çœ‹å‡ºåªæœ‰ä¾èµ–å’Œ upstream tarballï¼Œæ²¡æåˆ° service/configã€‚
* Qdrant æœ¬èº«å¸¦æœ‰å†…ç½®é»˜è®¤é…ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ä¼šç›´æ¥ç”¨å†…ç½®é»˜è®¤å€¼å¯åŠ¨ï¼Œåªæ˜¯åœ¨æ—¥å¿—é‡Œ warn ä¸€ä¸‹â€œæ‰¾ä¸åˆ° config/configâ€ã€‚

å®˜æ–¹æ–‡æ¡£ä¹Ÿè¯´æ˜äº†ï¼šé…ç½®æ–‡ä»¶æ˜¯ **å¯é€‰** çš„ï¼Œä¼šæŒ‰ä»¥ä¸‹é¡ºåºæŸ¥æ‰¾ï¼ˆç›¸å¯¹è·¯å¾„ `config/config.yaml`ã€`config/{RUN_MODE}.yaml`ã€`config/local.yaml` æˆ–è€…ä½ æ˜¾å¼ä¼  `--config-path`ï¼‰ã€‚

æ‰€ä»¥ä½ ç°åœ¨çœ‹åˆ°ï¼š

* æ²¡ `/etc/qdrant/config.yaml`ï¼šâ†’ AUR æ²¡å¸®ä½ åˆ›å»ºï¼›
* æ²¡ `qdrant.service`ï¼šâ†’ AUR ä¹Ÿæ²¡æä¾› systemd unitï¼›
* ä½†ç›´æ¥åœ¨ shell é‡Œè·‘ `qdrant` åº”è¯¥èƒ½èµ·æ¥ï¼ˆèµ°é»˜è®¤é…ç½®ï¼‰ã€‚

### æ–¹æ¡ˆ Aï¼šå…ˆä¸æŠ˜è…¾é…ç½®ï¼Œç›´æ¥æ‰‹åŠ¨è·‘

æœ€ç®€å•ï¼š

```bash
qdrant
# é»˜è®¤ä¼šç”¨å†…ç½®é…ç½®ï¼Œåœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»º ./storage ç­‰
# ç›‘å¬ 6333/6334
```

ä½ å¯ä»¥åœ¨å¦ä¸€ä¸ªç»ˆç«¯é‡Œï¼š

```bash
curl http://127.0.0.1:6333/healthz
```

ç¡®è®¤æ˜¯å¦ OKã€‚

ç¼ºç‚¹ï¼šæ²¡æœ‰å®ˆæŠ¤è¿›ç¨‹ã€æ²¡æœ‰å¼€æœºè‡ªå¯ã€‚

---

### æ–¹æ¡ˆ Bï¼šè‡ªå·±å†™ä¸€ä¸ª systemd æœåŠ¡ï¼ˆæ¨èï¼‰

1. åˆ›å»ºæ•°æ®ç›®å½• & ä¸“ç”¨ç”¨æˆ·ï¼ˆå¯é€‰ï¼Œä½†æ›´å¹²å‡€ä¸€äº›ï¼‰ï¼š

```bash
sudo useradd -r -s /usr/bin/nologin -d /var/lib/qdrant qdrant
sudo mkdir -p /var/lib/qdrant
sudo chown -R qdrant:qdrant /var/lib/qdrant
```

2. å†™ä¸€ä¸ªæœ€ç®€ systemd unitï¼š`/etc/systemd/system/qdrant.service`

```ini
[Unit]
Description=Qdrant vector database
After=network.target

[Service]
User=qdrant
Group=qdrant
WorkingDirectory=/var/lib/qdrant
ExecStart=/usr/bin/qdrant
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

> è¿™é‡Œæ²¡æœ‰æŒ‡å®š configï¼ŒQdrant ä¼šåœ¨ `WorkingDirectory` ä¸‹é¢æ‰¾ `config/...`ï¼Œæ‰¾ä¸åˆ°å°±ç”¨å†…ç½®é»˜è®¤å€¼ã€‚

3. å¯åŠ¨ï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl enable --now qdrant
sudo systemctl status qdrant
```

---

### æ–¹æ¡ˆ Cï¼šè‡ªå·±æ”¾ä¸€ä¸ª config.yaml å†ç”¨ `--config-path`

å¦‚æœä½ æƒ³æŠŠæ•°æ®ã€ç«¯å£ç­‰å†™æ­»åœ¨é…ç½®é‡Œï¼Œå¯ä»¥ï¼š

1. å»ºç›®å½•ï¼š

```bash
sudo mkdir -p /etc/qdrant
sudo chown qdrant:qdrant /etc/qdrant
```

2. å†™ `/etc/qdrant/config.yaml`ï¼ˆå¯ä»¥ä»å®˜æ–¹æ–‡æ¡£é‡Œçš„ç¤ºä¾‹æ‹·ä¸€ä»½å‡è‚¥ç‰ˆï¼‰ï¼š

```yaml
log_level: INFO
storage:
  storage_path: /var/lib/qdrant/storage
  snapshots_path: /var/lib/qdrant/snapshots

service:
  host: 0.0.0.0     # å¦‚æœå±€åŸŸç½‘å…¶å®ƒæœºå™¨ä¹Ÿè¦è¿å°±è¿™æ ·
  http_port: 6333
  grpc_port: 6334
```

3. æ”¹ systemd unitï¼Œè®©å®ƒæ˜¾å¼æŒ‡å®š configï¼š

```ini
[Service]
User=qdrant
Group=qdrant
WorkingDirectory=/var/lib/qdrant
ExecStart=/usr/bin/qdrant --config-path /etc/qdrant/config.yaml
Restart=on-failure
LimitNOFILE=65536
```

ç„¶åï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl restart qdrant
```

---

### å°ç»“ä¸€ä¸‹ä½ çš„ä¸¤ä¸ªé—®é¢˜

1. **LlamaIndex vs Haystack**

   * ä»¥ä½ ç°åœ¨â€œArch + æœ¬åœ° RAG + è¿œç«¯ GPU LLM + Pythonâ€ä¸ºä¸»çš„ä¸ªäºº/å°è§„æ¨¡åœºæ™¯ï¼š
     â†’ **å…ˆé€‰ LlamaIndex æ›´é¡ºæ‰‹**ï¼›
     â†’ å°†æ¥åšå¤æ‚å¤šé˜¶æ®µ pipeline æˆ–ä¼ä¸šçº§æœåŠ¡ï¼Œå†è€ƒè™‘ Haystackã€‚

2. **qdrant-bin æ²¡æœ‰ service / config.yaml**

   * è¿™æ˜¯ AUR åŒ…çš„æ­£å¸¸æƒ…å†µï¼Œä¸æ˜¯ä½ è£…åäº†ï¼›
   * Qdrant æ²¡ config ä¹Ÿèƒ½æ­£å¸¸è·‘ï¼Œç”¨çš„æ˜¯å†…ç½®é»˜è®¤é…ç½®ï¼›
   * ä½ å¯ä»¥ï¼š

     * è¦ä¹ˆï¼šç›´æ¥ `qdrant` æ‰‹åŠ¨è·‘ï¼›
     * è¦ä¹ˆï¼šæŒ‰ä¸Šé¢çš„æ¨¡æ¿å†™ä¸€ä¸ª `qdrant.service`ï¼Œå¯é€‰å†åŠ  `/etc/qdrant/config.yaml` + `--config-path`ã€‚

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ä¸‹ä¸€æ­¥å¸®ä½ ï¼š

* æŠŠ **LlamaIndex + Qdrant + è¿œç¨‹ Ollama** çš„å®Œæ•´ç¤ºä¾‹é¡¹ç›®ç›®å½•ï¼ˆ`main.py`, `config/`, `systemd` æ–‡ä»¶ï¼‰å†™æˆä¸€å¥—ä½ å¯ä»¥ç›´æ¥ `git init` ç”¨çš„éª¨æ¶ã€‚
