# 第二部分：构建你的大语言模型智能体
## [第四章 智能体经典范式构建](https://datawhalechina.github.io/hello-agents/#/./chapter4/第四章%20智能体经典范式构建)
为了更好地组织智能体的“思考”与“行动”过程，业界涌现出了多种经典的架构范式:
- **ReAct (Reasoning and Acting)**： 一种将“思考”和“行动”紧密结合的范式，让智能体边想边做，动态调整。
- **Plan-and-Solve**： 一种“三思而后行”的范式，智能体首先生成一个完整的行动计划，然后严格执行。
- **Reflection**： 一种赋予智能体“反思”能力的范式，通过自我批判和修正来优化结果。

### 4.1 环境准备与基础工具定义
#### 4.1.1 安装依赖库
#### 4.1.2 配置 API 密钥
#### 4.1.3 封装基础 LLM 调用函数
演示代码 [llm_client.ipynb](../code/chapter4/llm_client.ipynb), [vLLM.md](./vLLM.md)
- OpenAI compatible, see [HuggingFaceHub](./HuggingFaceHub.md)
  * Local deploy & host: **hugging face + TGI (docker)**, **vLLM**, **Ollama**
  * Cloud based: OpenAI, Azure
- Google: Gemini, see [Gemini.md](./Gemini.md)

### 4.2 ReAct
#### 4.2.1 ReAct 的工作流程
- **Thought (思考)**： 这是智能体的“内心独白”。它会分析当前情况、分解任务、制定下一步计划，或者反思上一步的结果。
- **Action (行动)**： 这是智能体决定采取的具体动作，通常是调用一个外部工具，例如 `Search['华为最新款手机']`。
- **Observation (观察)**： 这是执行`Action`后从外部工具返回的结果，例如搜索结果的摘要或API的返回值。

![ReAct 范式中的“思考-行动-观察”协同循环](../docs/images/4-figures/4-1.png)
<center>图 4.1 ReAct 范式中的“思考-行动-观察”协同循环</center>

这种机制特别适用于以下场景：
- 需要外部知识的任务：如查询实时信息（天气、新闻、股价）、搜索专业领域的知识等。
- 需要精确计算的任务：将数学问题交给计算器工具，避免LLM的计算错误。
- 需要与API交互的任务：如操作数据库、调用某个服务的API来完成特定功能。

#### 4.2.2 工具的定义与实现
网页搜索工具: **SerpApi**
(1) 实现搜索工具的核心逻辑
一个良好定义的工具应包含以下三个核心要素：
- **名称 (Name)**： 一个简洁、唯一的标识符，供智能体在 `Action` 中调用，例如 `Search`。
- **描述 (Description)**： 一段清晰的自然语言描述，说明这个工具的用途。这是**整个机制中最关键的部分**，因为大语言模型会依赖这段描述来判断何时使用哪个工具。
- **执行逻辑 (Execution Logic)**： 真正执行任务的函数或方法。

(2) 构建通用的工具执行器
(3) 测试

#### 4.2.3 ReAct 智能体的编码实现
(1) 系统提示词设计
```
# ReAct 提示词模板
REACT_PROMPT_TEMPLATE = """
请注意，你是一个有能力调用外部工具的智能助手。

可用工具如下:
{tools}

请严格按照以下格式进行回应:

Thought: 你的思考过程，用于分析问题、拆解任务和规划下一步行动。
Action: 你决定采取的行动，必须是以下格式之一:
- `{{tool_name}}[{{tool_input}}]`:调用一个可用工具。
- `Finish[最终答案]`:当你认为已经获得最终答案时。
- 当你收集到足够的信息，能够回答用户的最终问题时，你必须在Action:字段后使用 finish(answer="...") 来输出最终答案。

现在，请开始解决以下问题:
Question: {question}
History: {history}
"""
```
这个模板定义了智能体与LLM之间交互的规范：
- **角色定义**： “你是一个有能力调用外部工具的智能助手”，设定了LLM的角色。
- **工具清单 ({tools})**： 告知LLM它有哪些可用的“手脚”。
- **格式规约 (Thought/Action)**： 这是最重要的部分，它强制LLM的输出具有结构性，使我们能通过代码精确解析其意图。
- **动态上下文 ({question}/{history})**： 将用户的原始问题和不断累积的交互历史注入，让LLM基于完整的上下文进行决策。

(2) 核心循环的实现
(3) 输出解析器的实现
(4) 工具调用与执行
(5) 观测结果的整合
(6) 运行实例与分析

#### 4.2.4 ReAct 的特点、局限性与调试技巧
(1) ReAct 的主要特点
- 高可解释性
- 动态规划与纠错能力
- 工具协同能力

(2) ReAct 的固有局限性
- 对LLM自身能力的强依赖
- 执行效率问题
- 提示词的脆弱性
- 可能陷入局部最优

(3) 调试技巧
- 检查完整的提示词
- 分析原始输出
- 验证工具的输入与输出
- 调整提示词中的示例 (Few-shot Prompting)
- 尝试不同的模型或参数

### 4.3 Plan-and-Solve
#### 4.3.1 Plan-and-Solve 的工作原理
Plan-and-Solve 将整个流程解耦为两个核心阶段
- **规划阶段 (Planning Phase)**: 首先，智能体会接收用户的完整问题。它的第一个任务不是直接去解决问题或调用工具，而是将问题分解，并制定出一个清晰、分步骤的行动计划。这个计划本身就是一次大语言模型的调用产物。
- **执行阶段 (Solving Phase)**: 在获得完整的计划后，智能体进入执行阶段。它会严格按照计划中的步骤，逐一执行。每一步的执行都可能是一次独立的 LLM 调用，或者是对上一步结果的加工处理，直到计划中的所有步骤都完成，最终得出答案。

![Plan-and-Solve 范式的两阶段工作流](../docs/images/4-figures/4-2.png)
<center>图 4.2 Plan-and-Solve 范式的两阶段工作流</center>

Plan-and-Solve 尤其适用于那些结构性强、可以被清晰分解的复杂任务，例如：
- **多步数学应用题**：需要先列出计算步骤，再逐一求解。
- **需要整合多个信息源的报告撰写**：需要先规划好报告结构（引言、数据来源A、数据来源B、总结），再逐一填充内容。
- **代码生成任务**：需要先构思好函数、类和模块的结构，再逐一实现。

#### 4.3.2 规划阶段
**我们的目标问题是**：“一个水果店周一卖出了15个苹果。周二卖出的苹果数量是周一的两倍。周三卖出的数量比周二少了5个。请问这三天总共卖出了多少个苹果？”
- **规划阶段**：首先，将问题分解为三个独立的计算步骤（计算周二销量、计算周三销量、计算总销量）。
- **执行阶段**：然后，严格按照计划，一步步执行计算，并将每一步的结果作为下一步的输入，最终得出总和。

#### 4.3.3 执行器与状态管理
执行器的提示词与规划器不同。它的目标不是分解问题，而是在已有上下文的基础上，专注解决当前这一个步骤。因此，提示词需要包含以下关键信息：
- **原始问题**： 确保模型始终了解最终目标。
- **完整计划**： 让模型了解当前步骤在整个任务中的位置。
- **历史步骤与结果**： 提供至今为止已经完成的工作，作为当前步骤的直接输入。
- **当前步骤**： 明确指示模型现在需要解决哪一个具体任务。

强化提示词:
- **PLANNER_PROMPT_TEMPLATE**: 步骤里不要带具体计算结果(避免大模型"嘴欠"剧透)
- **EXECUTOR_PROMPT_TEMPLATE**: 规定步骤输出纯文本格式(避免 Markdown / LaTex 中的特殊字符如$)
- 建议: 抽取数字用 Tool 去准确计算数学表达式!

#### 4.3.4 运行实例与分析

### 4.4 Reflection
Reflection 机制的核心思想，正是为智能体引入一种**事后（post-hoc）的自我校正循环**，使其能够像人类一样，审视自己的工作，发现不足，并进行迭代优化。

#### 4.4.1 Reflection 机制的核心思想
其核心工作流程可以概括为一个简洁的三步循环：**执行 -> 反思 -> 优化**。
- **执行 (Execution)**：首先，智能体使用我们熟悉的方法（如 ReAct 或 Plan-and-Solve）尝试完成任务，生成一个初步的解决方案或行动轨迹。这可以看作是“初稿”。
- **反思 (Reflection)**：接着，智能体进入反思阶段。
  * **事实性错误**：是否存在与常识或已知事实相悖的内容？
  * **逻辑漏洞**：推理过程是否存在不连贯或矛盾之处？
  * **效率问题**：是否有更直接、更简洁的路径来完成任务？
  * **遗漏信息**：是否忽略了问题的某些关键约束或方面？ 根据评估，它会生成一段结构化的反馈 (Feedback)，指出具体的问题所在和改进建议。
- **优化 (Refinement)**：最后，智能体将“初稿”和“反馈”作为新的上下文，再次调用大语言模型，要求它根据反馈内容对初稿进行修正，生成一个更完善的“修订稿”。

![Reflection 机制中的“执行-反思-优化”迭代循环](../docs/images/4-figures/4-3.png)
<center>图 4.3 Reflection 机制中的“执行-反思-优化”迭代循环</center>

#### 4.4.2 案例设定与记忆模块设计
这一步实践我们主要完成**代码生成与迭代优化。**
- **存在明确的优化路径**：大语言模型初次生成的代码很可能是一个简单但效率低下的递归实现。
- **反思点清晰**：可以通过反思发现其“时间复杂度过高”或“存在重复计算”的问题。
- **优化方向明确**：可以根据反馈，将其优化为更高效的迭代版本或使用备忘录模式的版本。

#### 4.4.3 Reflection 智能体的编码实现
（1）提示词设计
- **初始执行提示词 (Execution Prompt)** ：这是智能体首次尝试解决问题的提示词，内容相对直接，只要求模型完成指定任务。
- **反思提示词 (Reflection Prompt)** ：这个提示词是 Reflection 机制的灵魂。它指示模型扮演“代码评审员”的角色，对上一轮生成的代码进行批判性分析，并提供具体的、可操作的反馈。
- **优化提示词 (Refinement Prompt)** ：当收到反馈后，这个提示词将引导模型根据反馈内容，对原有代码进行修正和优化。

（2）智能体封装与实现

#### 4.4.4 运行实例与分析
[实例](../code/chapter4/Reflection.py)展示了 Reflection 机制是如何驱动智能体进行深度优化的:
- 有效的“批判”是优化的前提
- 迭代式改进
- 收敛与终止
一个设计良好的 Reflection 机制，其价值不仅在于修复错误，更在于**驱动解决方案在质量和效率上实现阶梯式的提升**，这使其成为构建复杂、高质量智能体的关键技术之一。

#### 4.4.5 Reflection 机制的成本收益分析
（1）主要成本
- 模型调用开销增加
- 任务延迟显著提高
- 提示工程复杂度上升

（2）核心收益
- 解决方案质量的跃迁
- 鲁棒性与可靠性增强
Reflection 机制是一种典型的“以成本换质量”的策略。它非常适合那些**对最终结果的质量、准确性和可靠性有极高要求，且对任务完成的实时性要求相对宽松**的场景。例如:
- 生成关键的业务代码或技术报告。
- 在科学研究中进行复杂的逻辑推演。
- 需要深度分析和规划的决策支持系统。

### 4.5 本章小结
三种业界经典的智能体构建范式: **ReAct**、**Plan-and-Solve** 与 **Reflection**。

## [第五章 基于低代码平台的智能体搭建](https://datawhalechina.github.io/hello-agents/#/./chapter5/第五章%20基于低代码平台的智能体搭建)
### 5.1 平台化构建的兴起
#### 5.1.1 为何需要低代码平台
- 降低技术门槛
- 提升开发效率
- 提供更优的可视化与可观测性
- 标准化与最佳实践沉淀

#### 5.1.2 低代码平台的选择
**Coze** (by 字节跳动)
- 适用人群：AI 应用的入门用户、产品经理、运营人员，以及希望快速将创意变为可交互产品的个人创作者。
**Dify**
- 适用人群：有一定技术背景的开发者、需要构建可扩展的企业级 AI 应用的团队。
**n8n**
- 适用人群：需要将 AI 能力深度整合进现有业务流程、实现高度定制化自动化的开发者和企业。

### 5.2 平台一：Coze (https://www.coze.cn/)
#### 5.2.1 Coze 的功能模块
#### 5.2.2 构建“每日AI简报”助手
#### 5.2.3 Coze 的优势与局限性分析
**优势:**
- 强大的插件生态系统
- 直观的可视化编排
- 灵活的提示词控制
- 便捷的多平台部署

**局限性:**
- 不支持MCP
- 部分插件配置的复杂度高
- 无法导入编排json文件

### 5.3 平台二：Dify (https://cloud.dify.ai/)
#### 5.3.1 Dify 的介绍与生态
#### 5.3.2 构建一个超级智能体个人助手
#### 5.3.3 Dify 的优势与局限性分析
**核心优势​**
- 全栈式开发体验: RAG + AI flow + models + MCP
- 低代码与高扩展性的平衡
- 企业级安全与合规
- 丰富的工具集成能力: 支持 9000 + 工具和 API 扩展
- 活跃的开源社区

**主要局限​**
- 学习曲线较陡
- 性能瓶颈: Dify 系统的核心服务端组件由 Python 语言实现，与 C++、Golang、Rust 等语言相比，性能表现相对较差​
- 多模态支持不足
- 企业版成本较高
- API 兼容性问题: Dify 的 API 格式不兼容 OpenAI

### 5.4 平台三：n8n
#### 5.4.1 n8n 的节点与工作流
n8n 的世界由两个最基本的概念构成：**节点 (Node)** 和 **工作流 (Workflow)**

#### 5.4.2 搭建智能邮件助手
整个过程模拟了一个更高级的决策逻辑：`接收 -> AI Agent (思考 -> 决策 -> 工具调用) -> 回复`，如图5.38所示。
![一体化智能邮件 Agent 架构示意图](../docs/images/5-figures/n8n-01.png) (c542p1.png)
<center>图 5.38 一体化智能邮件 Agent 架构示意图</center>

整个搭建过程分为两个核心步骤：
- **准备 Agent 的“记忆”**：创建一个独立的流程，为 Agent 加载私有知识库。
- **构建 Agent 主体**：创建接收邮件、思考并回复的主工作流。

#### 5.4.3 构建 Agent 的私有知识库
(1) 定义知识源
(2) 文本向量化 (Embeddings)
(3) 存入向量存储

#### 5.4.4 创建 Agent 主工作流
(1) 配置 Gmail 触发器
(2) 配置 AI Agent 节点
(3) 配置 Agent 的工具
(4) 发送最终回复

#### 5.4.5 n8n 的优势与局限性分析
<center>表 5.1 n8n 平台的优势与局限性总结</center>

| **类别**   | **优势**                                 | **局限性**                            |
|-----------|------------------------------------------|--------------------------------------|
| 开发效率   | 可视化搭建、低代码、上手快、原型验证迅速        | 复杂逻辑的调试和错误处理相对繁琐           |
| 功能强大   | 集成生态丰富，AI Agent 节点能力强，支持代码扩展 | 内置的内存存储不适用于生产环境的持久化需求  |
| 部署运维   | 支持自托管，数据隐私性好                      | 版本控制和多人协作不如传统代码开发流程成熟  |
| 性能      | 满足绝大多数自动化场景                        | 可能不适合超高并发的实时系统             |

### 5.5 本章小结
通过三个平台的对比实践，我们可以得出以下选型建议:
- 快速原型验证、非技术用户: 优先选择 Coze
- 企业级应用、复杂业务逻辑: 优先选择 Dify
- 深度业务集成、自动化流程: 优先选择 n8n

## [第六章 框架开发实践](https://datawhalechina.github.io/hello-agents/#/./chapter6/第六章%20框架开发实践)
### 6.1 从手动实现到框架开发
#### 6.1.1 为何需要智能体框架
- 提升代码复用与开发效率
- 实现核心组件的解耦与可扩展性
  * 模型层 (Model Layer)
  * 工具层 (Tool Layer)
  * 记忆层 (Memory Layer)
- 标准化复杂的状态管理
- 简化可观测性与调试过程

#### 6.1.2 主流框架的选型与对比 
如果说 LangChain 和 LlamaIndex 定义了第一代通用 LLM 应用框架的范式，那么新一代的框架则更加专注于解决特定领域的深层挑战，尤其是**多智能体协作 (Multi-Agent Collaboration)** 和 **复杂工作流控制 (Complex Workflow Control)**。
<center>表 6.1 四种智能体框架对比</center>

| 框架        | 核心概念                        | 主要优势                              | 典型应用场景                                    |
|-------------|-------------------------------|--------------------------------------|-----------------------------------------------|
| AutoGen     | 对话的智能体（Conversable Agent）| 自动化多智能体对话流，高度可定制的交互模式。| 自动化代码生成与测试、模拟产品开发流程。             |
| AgentScope  | 消息传递（Message Passing）     | 易用性强，工程化程度高，支持分布式部署。    | 构建复杂、可运维的大规模多智能体应用。              |
| CAMEL       | 角色扮演（Role-Playing）        | 极简的协作设定，通过初始化提示驱动自主对话。  | 探索性任务、创意生成、模拟特定领域专家协作。        |
| LangGraph   | 状态图（State Graph）           | 天然支持循环和条件分支，精确控制复杂工作流。  | 实现 Reflection、迭代式优化、需要人工介入的流程。 |

- **AutoGen**：AutoGen 的核心思想是通过对话实现协作。
- **AgentScope**：核心特点是**易用性**和**工程化**。内置的**消息传递机制**和对分布式部署的支持，使其非常适合构建和运维复杂、大规模的多智能体系统。
- **CAMEL**：CAMEL 提供了一种新颖的、名为**角色扮演 (Role-Playing)** 的协作方法。
- **LangGraph**：作为 LangChain 生态的扩展，LangGraph 另辟蹊径，将智能体的执行流程建模为**图 (Graph)**。

### 6.2 框架一：AutoGen
AutoGen 的设计哲学是 **"以对话驱动协作"**

#### 6.2.1 AutoGen 的核心机制
![AutoGen架构图](../docs/images/6-figures/02.png)
<center>图 6.1 AutoGen架构图</center>

(1) 框架结构的演进
- **分层设计**: 框架被拆分为两个核心模块：
  * autogen-core：作为框架的底层基础，封装了与语言模型交互、消息传递等核心功能。
  * autogen-agentchat：构建于 core 之上，提供了用于开发对话式智能体应用的高级接口，简化了多智能体应用的开发流程。 
- **异步优先**： 新架构全面转向异步编程 (async/await)。
(2) 核心智能体组件
- **AssistantAgent (助理智能体)**： 这是任务的主要解决者，其核心是封装了一个大型语言模型（LLM）。通过不同的系统消息（System Message），我们可以为其赋予不同的“专家”角色。
- **UserProxyAgent (用户代理智能体)**： 这是 AutoGen 中功能独特的组件。它扮演着双重角色：既是人类用户的“代言人”，负责发起任务和传达意图；又是一个可靠的“执行器”，可以配置为执行代码或调用工具，并将结果反馈给其他智能体。这种设计清晰地区分了“思考”（由 AssistantAgent 完成）与“行动”。
(3) 从 GroupChatManager 到 Team
`GroupChatManager` => `RoundRobinGroupChat`
- **轮询群聊 (RoundRobinGroupChat)**： 这是一种明确的、顺序化的对话协调机制。它会让参与的智能体按照预定义的顺序依次发言。
- **工作流**

#### 6.2.2 软件开发团队
#### 6.2.3 核心代码实现
#### 6.2.4 AutoGen 的优势与局限性分析
(1) 优势: 
- 无需为智能体团队设计复杂的状态机或控制流逻辑
- 框架允许通过系统消息（System Message）为每个智能体赋予高度专业化的角色
- 对于流程化任务，`RoundRobinGroupChat` 这样机制提供了清晰、可预测的协作流程。serProxyAgent 的设计为“人类在环”（Human-in-the-loop）提供了天然的接口。
(2) 局限性:
- 虽然 `RoundRobinGroupChat` 提供了顺序化的流程，但基于 LLM 的对话本质上具有不确定性。智能体可能会产生偏离预期的回复，导致对话走向意外的分支，甚至陷入循环。
- 当智能体团队的工作结果未达预期时，调试过程可能非常棘手。**“对话式调试”**难题
(3) 非 OpenAI 模型的配置补充:
如果你想使用非 OpenAI 系列的模型（如 DeepSeek、通义千问等），在 0.7.4 版本中需要在 OpenAIChatCompletionClient 的参数中传入模型信息字典。以 DeepSeek 为例：
```python
from autogen_ext.models.openai import OpenAIChatCompletionClient
model_client = OpenAIChatCompletionClient(
    model="deepseek-chat",
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com/v1",
    model_info={
        "function_calling": True,
        "max_tokens": 4096,
        "context_length": 32768,
        "vision": False,
        "json_output": True,
        "family": "deepseek",
        "structured_output": True,
    }
)
```

### 6.3 框架二：AgentScope (by 阿里巴巴达摩院)
AgentScope 则代表了另一种技术路径：**工程化优先的多智能体平台**。

#### 6.3.1 AgentScope 的设计
与 AutoGen 相比，AgentScope 的核心差异在于其**消息驱动的架构设计和工业级的工程实践**。AgentScope 选择了**组合式架构**和**消息驱动模式**。
Calls: 107 (@2025-11-26), Tokens: 129000/6400/135400
(1) 分层架构体系

![AgentScope架构图](../docs/images/6-figures/03.png)
<center>图 6.2 AgentScope架构图</center>
(2) 消息驱动
(3) 智能体生命周期管理
(4) 消息传递机制

#### 6.3.2 三国狼人杀游戏
(1) 架构设计与核心组件
- **游戏控制层 (Game Control Layer)**: 由一个 ThreeKingdomsWerewolfGame 类作为游戏的主控制器，负责维护全局状态（如玩家存活列表、当前游戏阶段）、推进游戏流程（调用夜晚阶段、白天阶段）以及裁定胜负。
- **智能体交互层 (Agent Interaction Layer)**: 完全由 MsgHub 驱动。所有智能体间的通信，无论是狼人间的秘密协商，还是白天的公开辩论，都通过消息中心进行路由和分发。
- **角色建模层 (Role Modeling Layer)**: 每个玩家都是一个基于 DialogAgent 的实例。我们通过精心设计的系统提示词，为每个智能体注入了“游戏角色”和“三国人格”的双重身份。

(2) 消息驱动的游戏流程
本案例最核心的设计是以**消息驱动**代替**状态机**来管理游戏流程。

(3) 用结构化输出约束游戏规则
(4) 角色建模的双重挑战
(5) 并发处理与容错机制

#### 6.3.3 AgentScope 的优势与局限性分析

### 6.4 框架三：CAMEL
#### 6.4.1 CAMEL 的自主协作
CAMEL 实现自主协作的基石是两大核心概念：**角色扮演 (Role-Playing)** 和 **引导性提示 (Inception Prompting)**。
(1) 角色扮演
在 CAMEL 最初的设计中，一个任务通常由两个智能体协作完成。这两个智能体被赋予了互补的、明确定义的“角色”。一个扮演 **“AI 用户” (AI User)**，负责提出需求、下达指令和构思任务步骤；另一个则扮演 **“AI 助理” (AI Assistant)**，负责根据指令执行具体操作和提供解决方案。
(2) 引导性提示
- 明确自身角色
- 告知协作者角色
- 定义共同目标
- 设定行为约束和沟通协议

![CAMEL创建股票机器人交易](../docs/images/6-figures/04.png)
<center>图 6.3 CAMEL创建股票机器人交易</center>

#### 6.4.2 AI科普电子书
[DigitalBookWriting.py](../code/chapter6/CAMEL/DigitalBookWriting.py) 最终因为本地模型 total token 不够而停止
```
openai.UnprocessableEntityError: Error code: 422 - {'error': 'Input validation error: `inputs` must have less than 8192 tokens. Given: 8386', 'error_type': 'validation'}
```

#### 6.4.3 CAMEL 的优势与局限性分析
(1) 优势
CAMEL 最大的优势在于其 **"轻架构、重提示"** 的设计哲学。相比 AutoGen 的复杂对话管理和 AgentScope 的分布式架构，CAMEL 通过精心设计的初始提示就能实现高质量的智能体协作。这种自然涌现的协作行为，往往比硬编码的工作流更加灵活和高效。
CAMEL 已经远不止是一个简单的双智能体协作框架，目前已经具备：
- **多模态能力**：支持文本、图像、音频等多种模态的智能体协作
- **工具集成**：内置了丰富的工具库，包括搜索、计算、代码执行等
- **模型适配**：支持 OpenAI、Anthropic、Google、开源模型等多种 LLM 后端
- **生态联动**：与 LangChain、CrewAI、AutoGen 等主流框架实现了互操作性

(2) 主要局限性
* 对提示工程的高度依赖
  - **提示设计门槛**：需要深入理解目标领域和 LLM 的行为特性
  - **调试复杂性**：当协作效果不佳时，很难定位是角色定义、任务描述还是交互规则的问题
  - **一致性挑战**：不同的 LLM 对相同提示的理解可能存在差异

* 协作规模的限制
  - **对话管理**：缺乏像 AutoGen 那样的复杂对话路由机制
  - **状态同步**：没有 AgentScope 那样的分布式状态管理能力
  - **冲突解决**：当多个智能体意见分歧时，缺乏有效的仲裁机制

* 任务适用性的边界
  - **严格流程控制**：对于需要精确步骤控制的任务，LangGraph 的图结构更合适
  - **大规模并发**：AgentScope 的消息驱动架构在高并发场景下更有优势
  - **复杂决策树**：AutoGen 的群聊模式在多方决策场景下更加灵活

### 6.5 框架四：LangGraph
#### 6.5.1 LangGraph 的结构梳理
LangGraph 将智能体的执行流程建模为一种**状态机（State Machine）**，并将其表示为**有向图（Directed Graph）**。
- 首先，是**全局状态（State）**
- 其次，是**节点（Nodes）**
- 最后，是**边（Edges）**

#### 6.5.2 三步问答助手
- **理解 (Understand)**：首先，分析用户的查询意图。
- **搜索 (Search)**：然后，模拟搜索与意图相关的信息。
- **回答 (Answer)**：最后，基于意图和搜索到的信息，生成最终答案。

#### 6.5.3 LangGraph 的优势与局限性分析
(1) 优势
- 这种设计的最大优势是高度的可控性与可预测性。对**循环（Cycles）的原生支持**。
(2) 局限性
- 需要开发者编写更多的**前期代码（Boilerplate）**。缺少了对话式智能体那种动态的、**“涌现”式的交互**。
- 调试过程同样存在挑战。

### 6.6 本章小结
- 设计的权衡：**“涌现式协作”**与 **“显式控制”**之间的选择。
- 第二个同样重要的维度：**工程化**

## [第七章 构建你的智能体框架](https://datawhalechina.github.io/hello-agents/#/./chapter7/第七章%20构建你的Agent框架)
### 7.1 框架整体架构设计
#### 7.1.1 为何需要自建Agent框架
(1) 市面框架的快速迭代与局限性
- 过度抽象的复杂性
- 快速迭代带来的不稳定性
- 黑盒化的实现逻辑
- 依赖关系的复杂性

(2) 从使用者到构建者的能力跃迁
- 深度理解Agent工作原理
- 获得完全的控制权
- 培养系统设计能力

(3) 定制化需求与深度掌握的必要性
- 特定领域的优化需求
- 性能与资源的精确控制
- 学习与教学的透明性要求

#### 7.1.2 HelloAgents框架的设计理念
[HelloAgents](https://github.com/jjyaoao/HelloAgents)
(1) 轻量级与教学友好的平衡
(2) 基于标准API的务实选择
(3) 渐进式学习路径的精心设计
(4) 统一的“工具”抽象：万物皆为工具
为了彻底贯彻轻量级与教学友好的理念，HelloAgents在架构上做出了一个关键的简化：除了核心的Agent类，一切皆为Tools。在许多其他框架中需要独立学习的Memory（记忆）、RAG（检索增强生成）、RL（强化学习）、MCP（协议）等模块，在HelloAgents中都被统一抽象为一种“工具”。

#### 7.1.3 本章学习目标

### 7.2 HelloAgentsLLM扩展
#### 7.2.1 支持多提供商
#### 7.2.2 本地模型调用
#### 7.2.3 自动检测机制
<center>表 7.1 HelloAgentLLM不同版本特性对比</center>

| 特性         | 4.1.3 基础版本        | 7.2.1 扩展版本           |
|--------------|------------------------|---------------------------|
| 支持提供商   | 仅兼容 OpenAI          | 12+ 种提供商              |
| 配置方式     | 手动配置                | 智能检测 + 环境变量       |
| 本地模型     | 不支持                  | 完整支持                  |
| 错误处理     | 基础异常                | 完善的异常体系            |
| 默认模型     | 固定模型                | 智能选择                  |
| 扩展性       | 有限                    | 高度可扩展               |

### 7.3 框架接口实现
#### 7.3.1 Message 类
#### 7.3.2 Config 类
#### 7.3.3 Agent 抽象基类

### 7.4 Agent范式的框架化实现
#### 7.4.1 SimpleAgent
#### 7.4.2 ReActAgent
#### 7.4.3 ReflectionAgent
#### 7.4.4 PlanAndSolveAgent
<center>表 7.2 Agent不同章节实现对比</center>

| 提升维度     | 第四章独立实现             | 7.4 框架化实现              |
|--------------|-----------------------------|------------------------------|
| 代码复用     | 每个 Agent 独立实现         | 共享基础组件                 |
| 接口统一     | 各自定义接口                 | 统一的 Agent 接口            |
| 配置管理     | 硬编码或简单参数             | Config 对象统一管理          |
| 历史管理     | 各自实现                     | 标准化 Message 系统          |
| 扩展性       | 需要重复开发                 | 可扩展                       |
| 测试友好     | 难以单独测试组件             | 组件化便于测试               |
| 维护成本     | 高（重复代码多）             | 低（共享基础设施）           |

#### 7.4.5 FunctionCallAgent

### 7.5 工具系统
#### 7.5.1 工具基类与注册机制设计
#### 7.5.2 自定义工具开发
#### 7.5.3 多源搜索工具
#### 7.5.4 工具系统的高级特性

### 7.6 本章小结