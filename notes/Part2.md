# 第二部分：构建你的大语言模型智能体
## [第四章 智能体经典范式构建](https://datawhalechina.github.io/hello-agents/#/./chapter4/第四章%20智能体经典范式构建)
为了更好地组织智能体的“思考”与“行动”过程，业界涌现出了多种经典的架构范式:
- **ReAct (Reasoning and Acting)**： 一种将“思考”和“行动”紧密结合的范式，让智能体边想边做，动态调整。
- **Plan-and-Solve**： 一种“三思而后行”的范式，智能体首先生成一个完整的行动计划，然后严格执行。
- **Reflection**： 一种赋予智能体“反思”能力的范式，通过自我批判和修正来优化结果。

### 4.1 环境准备与基础工具定义
#### 4.1.1 安装依赖库
#### 4.1.2 配置 API 密钥
#### 4.1.3 封装基础 LLM 调用函数
演示代码 [llm_client.ipynb](../code/chapter4/llm_client.ipynb), [vLLM.md](./vLLM.md)
- OpenAI compatible, see [HuggingFaceHub](./HuggingFaceHub.md)
  * Local deploy & host: **hugging face + TGI (docker)**, **vLLM**, **Ollama**
  * Cloud based: OpenAI, Azure
- Google: Gemini, see [Gemini.md](./Gemini.md)

### 4.2 ReAct
#### 4.2.1 ReAct 的工作流程
- **Thought (思考)**： 这是智能体的“内心独白”。它会分析当前情况、分解任务、制定下一步计划，或者反思上一步的结果。
- **Action (行动)**： 这是智能体决定采取的具体动作，通常是调用一个外部工具，例如 `Search['华为最新款手机']`。
- **Observation (观察)**： 这是执行`Action`后从外部工具返回的结果，例如搜索结果的摘要或API的返回值。

![图 4.1 ReAct 范式中的“思考-行动-观察”协同循环](c421p1.png)
<center>图 4.1 ReAct 范式中的“思考-行动-观察”协同循环</center>

这种机制特别适用于以下场景：
- 需要外部知识的任务：如查询实时信息（天气、新闻、股价）、搜索专业领域的知识等。
- 需要精确计算的任务：将数学问题交给计算器工具，避免LLM的计算错误。
- 需要与API交互的任务：如操作数据库、调用某个服务的API来完成特定功能。

#### 4.2.2 工具的定义与实现
网页搜索工具: **SerpApi**
(1) 实现搜索工具的核心逻辑
一个良好定义的工具应包含以下三个核心要素：
- **名称 (Name)**： 一个简洁、唯一的标识符，供智能体在 `Action` 中调用，例如 `Search`。
- **描述 (Description)**： 一段清晰的自然语言描述，说明这个工具的用途。这是**整个机制中最关键的部分**，因为大语言模型会依赖这段描述来判断何时使用哪个工具。
- **执行逻辑 (Execution Logic)**： 真正执行任务的函数或方法。

(2) 构建通用的工具执行器
(3) 测试

#### 4.2.3 ReAct 智能体的编码实现
(1) 系统提示词设计
```
# ReAct 提示词模板
REACT_PROMPT_TEMPLATE = """
请注意，你是一个有能力调用外部工具的智能助手。

可用工具如下:
{tools}

请严格按照以下格式进行回应:

Thought: 你的思考过程，用于分析问题、拆解任务和规划下一步行动。
Action: 你决定采取的行动，必须是以下格式之一:
- `{{tool_name}}[{{tool_input}}]`:调用一个可用工具。
- `Finish[最终答案]`:当你认为已经获得最终答案时。
- 当你收集到足够的信息，能够回答用户的最终问题时，你必须在Action:字段后使用 finish(answer="...") 来输出最终答案。

现在，请开始解决以下问题:
Question: {question}
History: {history}
"""
```
这个模板定义了智能体与LLM之间交互的规范：
- **角色定义**： “你是一个有能力调用外部工具的智能助手”，设定了LLM的角色。
- **工具清单 ({tools})**： 告知LLM它有哪些可用的“手脚”。
- **格式规约 (Thought/Action)**： 这是最重要的部分，它强制LLM的输出具有结构性，使我们能通过代码精确解析其意图。
- **动态上下文 ({question}/{history})**： 将用户的原始问题和不断累积的交互历史注入，让LLM基于完整的上下文进行决策。

(2) 核心循环的实现
(3) 输出解析器的实现
(4) 工具调用与执行
(5) 观测结果的整合
(6) 运行实例与分析

#### 4.2.4 ReAct 的特点、局限性与调试技巧
(1) ReAct 的主要特点
- 高可解释性
- 动态规划与纠错能力
- 工具协同能力

(2) ReAct 的固有局限性
- 对LLM自身能力的强依赖
- 执行效率问题
- 提示词的脆弱性
- 可能陷入局部最优

(3) 调试技巧
- 检查完整的提示词
- 分析原始输出
- 验证工具的输入与输出
- 调整提示词中的示例 (Few-shot Prompting)
- 尝试不同的模型或参数

### 4.3 Plan-and-Solve
#### 4.3.1 Plan-and-Solve 的工作原理
Plan-and-Solve 将整个流程解耦为两个核心阶段
- **规划阶段 (Planning Phase)**: 首先，智能体会接收用户的完整问题。它的第一个任务不是直接去解决问题或调用工具，而是将问题分解，并制定出一个清晰、分步骤的行动计划。这个计划本身就是一次大语言模型的调用产物。
- **执行阶段 (Solving Phase)**: 在获得完整的计划后，智能体进入执行阶段。它会严格按照计划中的步骤，逐一执行。每一步的执行都可能是一次独立的 LLM 调用，或者是对上一步结果的加工处理，直到计划中的所有步骤都完成，最终得出答案。

![图 4.2 Plan-and-Solve 范式的两阶段工作流](c431p1.png)
<center>图 4.2 Plan-and-Solve 范式的两阶段工作流</center>

Plan-and-Solve 尤其适用于那些结构性强、可以被清晰分解的复杂任务，例如：
- **多步数学应用题**：需要先列出计算步骤，再逐一求解。
- **需要整合多个信息源的报告撰写**：需要先规划好报告结构（引言、数据来源A、数据来源B、总结），再逐一填充内容。
- **代码生成任务**：需要先构思好函数、类和模块的结构，再逐一实现。

#### 4.3.2 规划阶段
**我们的目标问题是**：“一个水果店周一卖出了15个苹果。周二卖出的苹果数量是周一的两倍。周三卖出的数量比周二少了5个。请问这三天总共卖出了多少个苹果？”
- **规划阶段**：首先，将问题分解为三个独立的计算步骤（计算周二销量、计算周三销量、计算总销量）。
- **执行阶段**：然后，严格按照计划，一步步执行计算，并将每一步的结果作为下一步的输入，最终得出总和。

#### 4.3.3 执行器与状态管理
执行器的提示词与规划器不同。它的目标不是分解问题，而是在已有上下文的基础上，专注解决当前这一个步骤。因此，提示词需要包含以下关键信息：
- **原始问题**： 确保模型始终了解最终目标。
- **完整计划**： 让模型了解当前步骤在整个任务中的位置。
- **历史步骤与结果**： 提供至今为止已经完成的工作，作为当前步骤的直接输入。
- **当前步骤**： 明确指示模型现在需要解决哪一个具体任务。

强化提示词:
- **PLANNER_PROMPT_TEMPLATE**: 步骤里不要带具体计算结果(避免大模型"嘴欠"剧透)
- **EXECUTOR_PROMPT_TEMPLATE**: 规定步骤输出纯文本格式(避免 Markdown / LaTex 中的特殊字符如$)
- 建议: 抽取数字用 Tool 去准确计算数学表达式!

#### 4.3.4 运行实例与分析

### 4.4 Reflection
Reflection 机制的核心思想，正是为智能体引入一种**事后（post-hoc）的自我校正循环**，使其能够像人类一样，审视自己的工作，发现不足，并进行迭代优化。

#### 4.4.1 Reflection 机制的核心思想
其核心工作流程可以概括为一个简洁的三步循环：**执行 -> 反思 -> 优化**。
- **执行 (Execution)**：首先，智能体使用我们熟悉的方法（如 ReAct 或 Plan-and-Solve）尝试完成任务，生成一个初步的解决方案或行动轨迹。这可以看作是“初稿”。
- **反思 (Reflection)**：接着，智能体进入反思阶段。
  * **事实性错误**：是否存在与常识或已知事实相悖的内容？
  * **逻辑漏洞**：推理过程是否存在不连贯或矛盾之处？
  * **效率问题**：是否有更直接、更简洁的路径来完成任务？
  * **遗漏信息**：是否忽略了问题的某些关键约束或方面？ 根据评估，它会生成一段结构化的反馈 (Feedback)，指出具体的问题所在和改进建议。
- **优化 (Refinement)**：最后，智能体将“初稿”和“反馈”作为新的上下文，再次调用大语言模型，要求它根据反馈内容对初稿进行修正，生成一个更完善的“修订稿”。

![图 4.3 Reflection 机制中的“执行-反思-优化”迭代循环](c441p1.png)
<center>图 4.3 Reflection 机制中的“执行-反思-优化”迭代循环</center>

#### 4.4.2 案例设定与记忆模块设计
这一步实践我们主要完成**代码生成与迭代优化。**
- **存在明确的优化路径**：大语言模型初次生成的代码很可能是一个简单但效率低下的递归实现。
- **反思点清晰**：可以通过反思发现其“时间复杂度过高”或“存在重复计算”的问题。
- **优化方向明确**：可以根据反馈，将其优化为更高效的迭代版本或使用备忘录模式的版本。

#### 4.4.3 Reflection 智能体的编码实现
（1）提示词设计
- **初始执行提示词 (Execution Prompt)** ：这是智能体首次尝试解决问题的提示词，内容相对直接，只要求模型完成指定任务。
- **反思提示词 (Reflection Prompt)** ：这个提示词是 Reflection 机制的灵魂。它指示模型扮演“代码评审员”的角色，对上一轮生成的代码进行批判性分析，并提供具体的、可操作的反馈。
- **优化提示词 (Refinement Prompt)** ：当收到反馈后，这个提示词将引导模型根据反馈内容，对原有代码进行修正和优化。

（2）智能体封装与实现

#### 4.4.4 运行实例与分析
[实例](../code/chapter4/Reflection.py)展示了 Reflection 机制是如何驱动智能体进行深度优化的:
- 有效的“批判”是优化的前提
- 迭代式改进
- 收敛与终止
一个设计良好的 Reflection 机制，其价值不仅在于修复错误，更在于**驱动解决方案在质量和效率上实现阶梯式的提升**，这使其成为构建复杂、高质量智能体的关键技术之一。

#### 4.4.5 Reflection 机制的成本收益分析
（1）主要成本
- 模型调用开销增加
- 任务延迟显著提高
- 提示工程复杂度上升

（2）核心收益
- 解决方案质量的跃迁
- 鲁棒性与可靠性增强
Reflection 机制是一种典型的“以成本换质量”的策略。它非常适合那些**对最终结果的质量、准确性和可靠性有极高要求，且对任务完成的实时性要求相对宽松**的场景。例如:
- 生成关键的业务代码或技术报告。
- 在科学研究中进行复杂的逻辑推演。
- 需要深度分析和规划的决策支持系统。

### 4.5 本章小结
三种业界经典的智能体构建范式: **ReAct**、**Plan-and-Solve** 与 **Reflection**。

